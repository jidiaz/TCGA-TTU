{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a77706c-fc17-4792-9561-95978055b04f",
   "metadata": {},
   "source": [
    "<h2><font color=\"#004D7F\" size=6>TCGA Data Analysis Tool 1.0 </font></h2>\n",
    "<h3><font color=\"#004D7F\" size=4>- Jorge Iván Díaz Riaño PhD(c)  </font></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9788d9a2-d16e-482b-957e-a6f5410bfaf5",
   "metadata": {},
   "source": [
    "<h1><font color=\"#004D7F\" size=4>1. Loading and preprocessing data</font></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f9e020-51ea-4749-8a91-39c63f3134bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8f3477",
   "metadata": {},
   "source": [
    "<h1><font color=\"#004D7F\" size=4>1.1. Loading required packages and libraries </font></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed346cf-75ab-4aeb-b732-0fd6f367c634",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import silhouette_score\n",
    "from lifelines import KaplanMeierFitter\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import warnings\n",
    "import io\n",
    "from ipywidgets import FileUpload, Button\n",
    "from IPython.display import display\n",
    "from sklearn.cluster import DBSCAN\n",
    "from scipy.stats import expon\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75f316e",
   "metadata": {},
   "source": [
    "<h1><font color=\"#004D7F\" size=4>1.2. Creating directory data structure </font></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c18dcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "projectName = \"PAAD\"\n",
    "# Get the current working directory\n",
    "working_directory = os.getcwd()\n",
    "print(working_directory)\n",
    "# Get the current date\n",
    "current_date = datetime.now()\n",
    "# Format the date as YYMMDD\n",
    "formatted_date = current_date.strftime('%y%m%d')\n",
    "# Define directory paths\n",
    "output_directory = os.path.join(working_directory, f\"{formatted_date}_TCGA_{projectName}_Output\")\n",
    "overview_directory = os.path.join(output_directory, f\"{formatted_date}_TCGA_{projectName}_Overview\")\n",
    "toPlots_directory = os.path.join(overview_directory, f\"{formatted_date}_TCGA_{projectName}_Plots\")\n",
    "toPlotsCutoff_directory = os.path.join(toPlots_directory, f\"{formatted_date}_TCGA_{projectName}_Cutoff\")\n",
    "toData_directory = os.path.join(overview_directory, f\"{formatted_date}_TCGA_{projectName}_Data\")\n",
    "toDataCutoff_directory = os.path.join(toData_directory, f\"{formatted_date}_TCGA_{projectName}_Cutoff\")\n",
    "todea_directory = os.path.join(output_directory, f\"{formatted_date}_TCGA_{projectName}_DEA\")\n",
    "deainput_directory = os.path.join(todea_directory, f\"{formatted_date}_TCGA_{projectName}_DEA_Input\")\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "os.makedirs(overview_directory, exist_ok=True)\n",
    "os.makedirs(toPlots_directory, exist_ok=True)\n",
    "os.makedirs(toPlotsCutoff_directory, exist_ok=True)\n",
    "os.makedirs(toData_directory, exist_ok=True)\n",
    "os.makedirs(toDataCutoff_directory, exist_ok=True)\n",
    "os.makedirs(todea_directory, exist_ok=True)\n",
    "os.makedirs(deainput_directory, exist_ok=True)\n",
    "print(\"Directories created successfully:\")\n",
    "print(output_directory)\n",
    "print(overview_directory)\n",
    "print(toPlots_directory)\n",
    "print(toPlotsCutoff_directory)\n",
    "print(toData_directory)\n",
    "print(toDataCutoff_directory)\n",
    "print(todea_directory)\n",
    "print(deainput_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85cb85d",
   "metadata": {},
   "source": [
    "<h1><font color=\"#004D7F\" size=4>1.3. Loading input table </font></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88e62ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset=input(\"Enter path for csv file: \") #C:\\\\Users\\\\TTUSVM\\\\Documents\\\\GitHub\\\\TCGA-TTU\\\\TC3R\\\\Input\\MAGE-TCGA-GBM_tpm_clinical.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d534c0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace empty/invalid values with NaN\n",
    "data= pd.read_csv(dataset, sep=',')\n",
    "df = pd.DataFrame(data)\n",
    "df.replace(\"\\'--\", np.nan, inplace=True)\n",
    "df.replace('not reported', np.nan, inplace=True)\n",
    "df.replace('Not Reported', np.nan, inplace=True)\n",
    "df.set_index('sample', inplace=True)\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40aefc07-a164-4fa1-9c19-2b50edd7fc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of null data points\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd000a59-c031-46cf-a35c-bb4917219923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns with >0.8 NaN's\n",
    "df = df.loc[:, df.isnull().mean() < .8]\n",
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa85ab55-2828-4734-b654-7cc00bbb6d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()\n",
    "# Write DataFrame description to CSV\n",
    "df.describe().to_csv(os.path.join(toData_directory, 'DescriptiveStatistics.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5551fdfc-17d2-4da3-9fcd-0804e8a8d3ab",
   "metadata": {},
   "source": [
    "<h1><font color=\"#004D7F\" size=5>2. Visualization</font></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ba8ea7-44c5-4238-b493-d61bbc2325ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric = df.select_dtypes(include=['number'])\n",
    "# Reorder columns based on the provided order\n",
    "column_order = [\n",
    "    \"MAGEA1\", \"MAGEA2\", \"MAGEA2B\", \"MAGEA3\", \"MAGEA4\", \"MAGEA5\", \"MAGEA6\", \"MAGEA7P\", \"MAGEA8\", \"MAGEA9\",\n",
    "    \"MAGEA9B\", \"MAGEA10\", \"MAGEA11\", \"MAGEA12\", \"MAGEB1\", \"MAGEB2\", \"MAGEB3\", \"MAGEB4\", \"MAGEB5\", \"MAGEB6\",\n",
    "    \"MAGEB10\", \"MAGEB16\", \"MAGEB17\", \"MAGEB18\", \"MAGEC1\", \"MAGEC2\", \"MAGEC3\", \"CSAG1\", \"CSAG2\", \"CSAG3\", \"CSAG4\", \"MAGED1\", \"MAGED2\", \"TRO\",\"MAGED4\",\n",
    "    \"MAGED4B\", \"MAGEE1\", \"MAGEE2\", \"MAGEF1\", \"NSMCE3\",\"MAGEH1\", \"MAGEL2\", \"TRIM28\", \"NDN\"\n",
    "]\n",
    "#df_numeric = df_numeric[column_order]\n",
    "df_numeric=df_numeric[column_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad42b7aa-d35e-4504-aeda-2a6e53c27553",
   "metadata": {},
   "source": [
    "<h1><font color=\"#004D7F\" size=4>2.1 Distribution of TPMs expression.</font></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bd9889",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set colors\n",
    "colors_pastel = sns.color_palette(\"Set2\")\n",
    "\n",
    "def plot_gene_histograms_type1(gene_list):\n",
    "    num_genes = len(gene_list)\n",
    "    num_rows = (num_genes // 6) + (1 if num_genes % 6 != 0 else 0)  # Calculate number of rows\n",
    "    plt.figure(figsize=(15, 2 * num_rows))\n",
    "    for i, gene in enumerate(gene_list, start=1):\n",
    "        plt.subplot(num_rows, 6, i)\n",
    "        plt.hist(np.log10(df_numeric[gene] + 1), bins=20, color=colors_pastel[2], edgecolor='black')\n",
    "        plt.title(gene)\n",
    "        plt.xlabel('Log10(TPM+1)')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(toPlots_directory, 'type1_TPM_Expression_histogram.png'), dpi=300)  # Save as PNG with high quality\n",
    "    plt.show()\n",
    "    \n",
    "def plot_gene_histograms_type2(gene_list):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for gene in gene_list:\n",
    "        plt.subplot(5, 6, gene_list.index(gene) + 1)\n",
    "        plt.hist(np.log10(df_numeric[gene] + 1), bins=20, color=colors_pastel[5], edgecolor='black')  # Using color from palette\n",
    "        plt.title(gene)\n",
    "        plt.xlabel('Log10(TPM+1)')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(toPlots_directory, 'type2_TPM_Expression_histogram.png'), dpi=300)  # Save as PNG with high quality\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52380834",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Type1 = [\"MAGEA1\", \"MAGEA2\", \"MAGEA2B\", \"MAGEA3\", \"MAGEA4\", \"MAGEA5\", \"MAGEA6\", \"MAGEA7P\", \"MAGEA8\", \"MAGEA9\",\"MAGEA9B\", \"MAGEA10\", \"MAGEA11\", \"MAGEA12\", \"MAGEB1\", \"MAGEB2\", \"MAGEB3\", \"MAGEB4\", \"MAGEB5\", \"MAGEB6\",\n",
    "    \"MAGEB10\", \"MAGEB16\", \"MAGEB17\", \"MAGEB18\", \"MAGEC1\", \"MAGEC2\", \"MAGEC3\",\"CSAG1\", \"CSAG2\", \"CSAG3\", \"CSAG4\"]\n",
    "Type2 = [ \"MAGED1\", \"MAGED2\", \"TRO\",\"MAGED4\", \"MAGED4B\", \"MAGEE1\", \"MAGEE2\", \"MAGEF1\", \"NSMCE3\",\"MAGEH1\", \"MAGEL2\", \"TRIM28\", \"NDN\"]\n",
    "plot_gene_histograms_type1(Type1)\n",
    "plot_gene_histograms_type2(Type2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e618061e-f977-4d92-878e-3d1d79f1f485",
   "metadata": {},
   "source": [
    "<h1><font color=\"#004D7F\" size=4>2.2. Composition of Positive and Negative Tumors by MAGEs.</font></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc346925-aa16-421c-897f-ed120e14167e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "no_zero = df_numeric.astype(bool).sum(axis=0)\n",
    "zero = df_numeric.shape[0] - no_zero\n",
    "# New df to order output\n",
    "output_df = pd.DataFrame({'Positive_counts': no_zero, 'Negative_counts': zero})\n",
    "output_df['Total_counts'] = output_df['Positive_counts'] + output_df['Negative_counts']\n",
    "# Calculate percentages\n",
    "percentage_df = output_df[['Positive_counts', 'Negative_counts']].div(output_df['Total_counts'], axis=0) * 100\n",
    "# Concatenate percentages with original DataFrame\n",
    "output_df = pd.concat([output_df, percentage_df.add_suffix('_percentage')], axis=1)\n",
    "# Sort DataFrame by column names (alphabetical order)\n",
    "output_df = output_df.sort_index()\n",
    "finalTable= output_df[['Positive_counts','Positive_counts_percentage','Negative_counts','Negative_counts_percentage']]\n",
    "finalTable=finalTable.round(1)\n",
    "finalTable=finalTable.loc[column_order]\n",
    "finalTable.to_csv(os.path.join(toData_directory, 'MAGE_PosNeg_Composition.csv'))\n",
    "finalTable.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe82a98-0071-4c83-8f77-69b908cfea5e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Normalization\n",
    "total_counts = no_zero + zero\n",
    "positive_normalized = no_zero / total_counts\n",
    "positive_normalized= positive_normalized[column_order]\n",
    "negative_normalized = zero / total_counts\n",
    "negative_normalized= negative_normalized[column_order]\n",
    "# Set colors\n",
    "colors_pastel = sns.color_palette(\"Set2\")\n",
    "# Stacked barplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "positive_normalized.plot(kind='bar', color=colors_pastel[2], width=0.4, position=1, label='Positive')\n",
    "negative_normalized.plot(kind='bar', color=colors_pastel[5], width=0.4, position=1, bottom=positive_normalized, label='Negative')\n",
    "plt.title('Composition of Positive and Negative Tumors for MAGE')\n",
    "plt.ylabel('Ratio of positive and negative samples')\n",
    "plt.legend()\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.xticks(rotation=90)\n",
    "plt.text(1.09, 0.8, 'n=169', horizontalalignment='center', verticalalignment='center', transform=plt.gca().transAxes)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(toPlots_directory, 'MAGE_PosNeg_Composition.png'), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff30a61-0080-4556-b22f-77b73839810c",
   "metadata": {},
   "source": [
    "<h1><font color=\"#004D7F\" size=5>3. Analysis </font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dea61b",
   "metadata": {},
   "source": [
    "<h1><font color=\"#004D7F\" size=4>3.1 Correlation</font></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7906f4ca-256e-471e-bdcf-83f35f03a36f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Perform correlation (Pearson)\n",
    "correlation = df_numeric.corr()\n",
    "plt.figure(figsize=(50, 50))\n",
    "ax = sns.heatmap(correlation, vmax=1, vmin=-1, square=True, annot=True, cmap='cividis')  # Correlations from -1 to 1, change to vmin\n",
    "correlation.to_csv(os.path.join(toData_directory, 'MAGE_PearsonCorrelation.csv'))\n",
    "plt.title('Correlation', fontsize=50)  # Increase title font size\n",
    "plt.xticks(rotation=90)  # Rotate X labels to 90 degrees\n",
    "plt.yticks(rotation=0)  # Rotate Y labels to default (0 degrees)\n",
    "# Increase font size of tick labels\n",
    "plt.tick_params(axis='x', labelsize=20)\n",
    "plt.tick_params(axis='y', labelsize=20)\n",
    "plt.savefig(os.path.join(toPlots_directory, 'MAGE_PearsonCorrelation_heatmap.png'), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9aea0e-dc32-4d75-85a3-97a75375e58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_redundant_pairs(df):\n",
    "    '''Get diagonal and lower triangular pairs of correlation matrix'''\n",
    "    pairs_to_drop = set()\n",
    "    cols = df.columns\n",
    "    for i in range(0, df.shape[1]):\n",
    "        for j in range(0, i+1):\n",
    "            pairs_to_drop.add((cols[i], cols[j]))\n",
    "    return pairs_to_drop\n",
    "\n",
    "def get_top_abs_correlations(df, n=5):\n",
    "    '''Get top absolute correlations'''\n",
    "    au_corr = df.corr().abs().unstack()\n",
    "    labels_to_drop = get_redundant_pairs(df)\n",
    "    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n",
    "    return au_corr[0:n]\n",
    "\n",
    "def get_bottom_abs_correlations(df, n=5):\n",
    "    '''Get bottom absolute correlations'''\n",
    "    au_corr = df.corr().unstack()\n",
    "    labels_to_drop = get_redundant_pairs(df)\n",
    "    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=True)\n",
    "    return au_corr[0:n]\n",
    "\n",
    "def get_all_abs_correlations(df):\n",
    "    '''Get all absolute correlations'''\n",
    "    au_corr = df.corr().abs().unstack()\n",
    "    labels_to_drop = get_redundant_pairs(df)\n",
    "    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n",
    "    return au_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5849e46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "numberCorr=int(input(\"Enter number of top/bottom correlations to be displayed: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3feecb2-beaa-46eb-a28d-d05587449b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print and save top correlations\n",
    "print('Top of correlations')\n",
    "topabs = get_top_abs_correlations(df_numeric, numberCorr)\n",
    "print(topabs)\n",
    "topabs.to_csv(os.path.join(toData_directory, f'Top_{numberCorr}_Correlation.csv'))\n",
    "\n",
    "# Print and save bottom correlations\n",
    "print('\\nBottom of correlations')\n",
    "botabs = get_bottom_abs_correlations(df_numeric, numberCorr)\n",
    "print(botabs)\n",
    "botabs.to_csv(os.path.join(toData_directory, f'Bot_{numberCorr}_Correlation.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040c5ba2",
   "metadata": {},
   "source": [
    "<h1><font color=\"#004D7F\" size=4>3.2 Cutoffs generation</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89953f97",
   "metadata": {},
   "source": [
    "<h1><font color=\"#004D7F\" size=4>3.2.1. Specific Gene</font></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac4e249",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(sorted_df, genes, value, optimal_cutoff, sample_names):\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    plt.bar(range(len(sorted_df[genes[0]])), np.log10(sorted_df[genes[0]] + 1), label='Expression values', color='skyblue')\n",
    "\n",
    "    # Plot lines at the points where the curve intersects the X-axis for PosNegCriteria and cutoff_value\n",
    "    posneg_criteria_value = np.log10(value+1)\n",
    "    plt.axhline(y=posneg_criteria_value, color='g', linestyle='--', label='PosNegCriteria')\n",
    "    \n",
    "    intersect_x_posneg = None\n",
    "    intersect_y_posneg = None\n",
    "    intersect_x_optimal = None\n",
    "    intersect_y_optimal = None\n",
    "\n",
    "    if optimal_cutoff is not None:\n",
    "        plt.axhline(y=np.log10(optimal_cutoff+1), color='b', linestyle='--', label='Optimal Cutoff')\n",
    "        # Find the index where the horizontal line intersects with the data for PosNegCriteria\n",
    "        intersect_index_posneg = np.argmin(np.abs(np.log10(sorted_df[genes[0]]+1) - posneg_criteria_value))\n",
    "        intersect_x_posneg = intersect_index_posneg\n",
    "        intersect_y_posneg = np.log10(sorted_df.iloc[intersect_index_posneg][genes[0]] + 1)\n",
    "        # Find the index where the horizontal line intersects with the data for Optimal Cutoff\n",
    "        intersect_index_optimal = np.argmin(np.abs(np.log10(sorted_df[genes[0]]+1) - np.log10(optimal_cutoff+1)))\n",
    "        intersect_x_optimal = intersect_index_optimal\n",
    "        intersect_y_optimal = np.log10(sorted_df.iloc[intersect_index_optimal][genes[0]] + 1)\n",
    "        # Plot vertical lines at the intersection points\n",
    "        plt.axvline(x=intersect_x_optimal, color='m', linestyle='-', label='Optimal Cutoff for high/medium expressed')\n",
    "    \n",
    "    if intersect_x_posneg is not None:\n",
    "        plt.axvline(x=intersect_x_posneg, color='r', linestyle='-', label='Cutoff to Positive Negative')\n",
    "        \n",
    "    plt.title(f\"Expression classification according with {genes[0]}\", fontsize=14)\n",
    "    plt.xlabel('Samples ID')\n",
    "    plt.ylabel('Log10(TPM+1)')\n",
    "    plt.xticks(range(len(sample_names)), sample_names, rotation=90)  # Rotate x-axis labels by 90 degrees\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(toPlotsCutoff_directory, f\"Cutoff_Generation_{genes}-gene_barplot.png\"), dpi=300)  # Save as PNG with high quality\n",
    "    plt.show()\n",
    "\n",
    "def find_optimal_cutoff(df, genes, value):\n",
    "    # Select only the columns corresponding to the genes\n",
    "    df_subset = df[genes]\n",
    "    # Drop rows under positive/negative threshold\n",
    "    df_subset = df_subset[(df_subset > value).any(axis=1)].dropna()\n",
    "    # Fit an exponential distribution to the data\n",
    "    params = expon.fit(df_subset.values.ravel())\n",
    "    # Generate samples from the fitted distribution\n",
    "    samples = expon.rvs(*params, size=10000)\n",
    "    # Cluster the samples using DBSCAN\n",
    "    dbscan = DBSCAN(eps=0.1, min_samples=5)\n",
    "    labels = dbscan.fit_predict(samples.reshape(-1, 1))\n",
    "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "    print(\"Finding optimal cutoff...\")\n",
    "    # Check if there are at least two clusters\n",
    "    if len(unique_labels) >= 2:\n",
    "        # Sort clusters by size\n",
    "        sorted_clusters = sorted(zip(unique_labels, counts), key=lambda x: x[1], reverse=True)\n",
    "        # Calculate the difference between the means of the two largest clusters\n",
    "        cluster1_indices = np.where(labels == sorted_clusters[0][0])[0]\n",
    "        cluster2_indices = np.where(labels == sorted_clusters[1][0])[0]\n",
    "        cluster1_mean = np.mean(samples[cluster1_indices])\n",
    "        cluster2_mean = np.mean(samples[cluster2_indices])\n",
    "        diff = np.abs(cluster1_mean - cluster2_mean)\n",
    "        # Update optimal cutoff and optimal difference if difference is maximized\n",
    "        optimal_cutoff = np.min([cluster1_mean, cluster2_mean])\n",
    "        optimal_diff = diff\n",
    "        optimal_labels = labels\n",
    "        min_input = np.min(df_subset)\n",
    "        max_input = np.max(df_subset)\n",
    "    else:\n",
    "        print(\"No optimal cutoff found greater than PosNegCriteria. Returning default values.\")\n",
    "        optimal_cutoff = None\n",
    "        optimal_diff = None\n",
    "        optimal_labels = None\n",
    "    return optimal_cutoff, optimal_diff, optimal_labels, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230f6ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "GeneName=input(\"Enter a Gene-name to be evaluated: \")\n",
    "PosNegCriteria=float(input(\"Enter a cut-off value to separate positive and negative tumors: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96003e00",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define the number of attempts\n",
    "max_attempts = 10\n",
    "attempt = 1\n",
    "print(f\"\\nProcessing {GeneName}\")\n",
    "while attempt <= max_attempts:\n",
    "    print(f\"Attempt {attempt}:\")\n",
    "    cutoff_value, optimal_diff, optimal_labels, optimal_centroids = find_optimal_cutoff(df_numeric, [GeneName], PosNegCriteria)\n",
    "    \n",
    "    if cutoff_value is not None and cutoff_value != -1:\n",
    "        log10_PosNegCriteria = np.log10(PosNegCriteria + 1)\n",
    "        normalized_cutoff_value = np.log10(cutoff_value + 1)    \n",
    "        # Sort dataframe based on the selected gene in descending order\n",
    "        sorted_df = df_numeric.sort_values(by=[GeneName][0], ascending=False)\n",
    "        sample_names = sorted_df.index  # Extract sample names from index\n",
    "        plot_results(sorted_df, [GeneName], PosNegCriteria, cutoff_value, sample_names)    \n",
    "        break  # Exit the loop if a valid cutoff value is found\n",
    "    else:\n",
    "        print(\"Optimal cutoff value not found or equal to -1. Retrying...\")\n",
    "        attempt += 1\n",
    "\n",
    "# If no valid cutoff value is found within max_attempts, handle accordingly\n",
    "if attempt > max_attempts:\n",
    "    print(\"Maximum attempts reached. Unable to find a valid cutoff value.\")\n",
    "    log10_PosNegCriteria = None\n",
    "    normalized_cutoff_value = None\n",
    "    optimal_cutoff = None\n",
    "    # Sort dataframe based on the selected gene in descending order\n",
    "    sorted_df = df_numeric.sort_values(by=[GeneName][0], ascending=False)\n",
    "    sample_names = sorted_df.index  # Extract sample names from index\n",
    "    plot_results(sorted_df, [GeneName], PosNegCriteria, optimal_cutoff, sample_names)\n",
    "    \n",
    "# Create a dictionary with the values\n",
    "data = {\n",
    "    \"TPM Positive/Negative threshold\": [PosNegCriteria],\n",
    "    \"log10(TPM+1) Positive/Negative threshold\": [log10_PosNegCriteria],\n",
    "    \"Optimal cutoff value\": [cutoff_value],\n",
    "    \"Normalized\": [normalized_cutoff_value]\n",
    "}\n",
    "\n",
    "# Convert the dictionary into a DataFrame\n",
    "result_df = pd.DataFrame(data)\n",
    "# Transpose the DataFrame\n",
    "result_df = result_df.transpose()\n",
    "# Rename the column and set the index name\n",
    "result_df.columns = [GeneName]\n",
    "result_df.index.name = \"Parameter\"\n",
    "result_df.to_csv(os.path.join(toDataCutoff_directory, f'OptimalCutoff_{GeneName}.csv'))\n",
    "#Print the DataFrame\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dc71e5",
   "metadata": {},
   "source": [
    "<h1><font color=\"#004D7F\" size=4>3.2.2. All set of Genes</font></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cb0a32",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialize a dictionary for basic parameters\n",
    "basic = {\n",
    "    \"TPM Positive/Negative threshold\": None,\n",
    "    \"log10(TPM+1) Positive/Negative threshold\": None,\n",
    "    \"Optimal cutoff value\": None,\n",
    "    \"Normalized\": None\n",
    "}\n",
    "\n",
    "# Add an index to the dictionary\n",
    "index = [\"Parameter\"]  # Define index values\n",
    "basic_with_index = {index[0]: list(basic.keys()), **basic}  # Combine index with basic dictionary\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "result_df = pd.DataFrame(basic_with_index)\n",
    "\n",
    "for i, gene in enumerate(column_order):\n",
    "    attempt = 1\n",
    "    print(f\"\\nProcessing {gene}\")\n",
    "    while attempt <= max_attempts:\n",
    "        print(f\"Attempt {attempt}:\")\n",
    "        cutoff_value, optimal_diff, optimal_labels, optimal_centroids = find_optimal_cutoff(df_numeric, [gene], PosNegCriteria)\n",
    "\n",
    "        if cutoff_value is not None and cutoff_value != -1:\n",
    "            log10_PosNegCriteria = np.log10(PosNegCriteria + 1)\n",
    "            normalized_cutoff_value = np.log10(cutoff_value + 1)\n",
    "            sorted_df = df_numeric.sort_values(by=gene, ascending=False)\n",
    "            sample_names = sorted_df.index\n",
    "            plot_results(sorted_df, [gene], PosNegCriteria, cutoff_value, sample_names)\n",
    "            break\n",
    "        else:\n",
    "            print(\"Optimal cutoff value not found or equal to -1. Retrying...\")\n",
    "            attempt += 1\n",
    "\n",
    "    if attempt > max_attempts:\n",
    "        print(\"Maximum attempts reached. Unable to find a valid cutoff value.\")\n",
    "        log10_PosNegCriteria = None\n",
    "        normalized_cutoff_value = None\n",
    "        sorted_df = df_numeric.sort_values(by=gene, ascending=False)\n",
    "        sample_names = sorted_df.index\n",
    "        # Assuming optimal_cutoff should be replaced with cutoff_value\n",
    "        plot_results(sorted_df, [gene], PosNegCriteria, cutoff_value, sample_names)\n",
    "\n",
    "    data = {\n",
    "        \"TPM Positive/Negative threshold\": [PosNegCriteria],\n",
    "        \"log10(TPM+1) Positive/Negative threshold\": [log10_PosNegCriteria],\n",
    "        \"Optimal cutoff value\": [cutoff_value],\n",
    "        \"Normalized\": [normalized_cutoff_value]\n",
    "    }\n",
    "\n",
    "    temp_df = pd.DataFrame(data)\n",
    "    temp_df = temp_df.transpose()\n",
    "    temp_df.columns = [gene]\n",
    "    result_df = pd.concat([result_df, temp_df], axis=1)\n",
    "\n",
    "result_df.to_csv(os.path.join(toDataCutoff_directory, 'OptimalCutoff_general.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5a554c",
   "metadata": {},
   "source": [
    "<h1><font color=\"#004D7F\" size=4>3.3. Heatmap</font></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a059dc5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define the diverging color palette\n",
    "custom_cmap = sns.diverging_palette(0, 240, as_cmap=True)\n",
    "# Sort the DataFrame based on GeneName column\n",
    "sorted_df_numeric = df_numeric.sort_values(by=GeneName, ascending=False)\n",
    "# Group rows into categories based on sorted values of GeneName\n",
    "sorted_df_numeric['Category'] = pd.cut(sorted_df_numeric[GeneName], bins=[-np.inf, PosNegCriteria, cutoff_value, np.inf], labels=['Negative', 'Medium expressed', 'Highly expressed'])\n",
    "# Map categories to colors\n",
    "color_map = {'Negative': 'lightsteelblue', 'Medium expressed': 'cornflowerblue', 'Highly expressed': 'navy'}\n",
    "# Convert category labels to colors\n",
    "row_colors = sorted_df_numeric['Category'].map(color_map)\n",
    "# Define function to normalize columns except 'Category'\n",
    "def normalize_column(col):\n",
    "    if col.name != 'Category':\n",
    "        return (col) / (col.max())\n",
    "    else:\n",
    "        return col\n",
    "# Normalize expression values except 'Category'\n",
    "normalized_df = sorted_df_numeric.apply(normalize_column, axis=0)\n",
    "normalized_df.to_csv(os.path.join(toData_directory, f'SortedExpression_{GeneName}_Heatmap.csv'))\n",
    "# Set font scale\n",
    "sns.set(font_scale=0.8)\n",
    "# Create the heatmap\n",
    "g = sns.clustermap(normalized_df.drop('Category', axis=1), center=0, cbar_kws={'label': 'Normalized Expression \\n(TPM/maxTPM[Gene])'}, row_cluster=False, col_cluster=False, xticklabels=True, yticklabels=True, cmap=custom_cmap, row_colors=row_colors )\n",
    "# Set font size for y-axis labels\n",
    "g.ax_heatmap.set_yticklabels(g.ax_heatmap.get_ymajorticklabels(), fontsize=3)\n",
    "# Set tick parameters\n",
    "g.ax_heatmap.tick_params(axis='y', which='major', labelsize=4)\n",
    "# Add text annotation indicating the ordering using GeneName\n",
    "g.ax_heatmap.text(0.5, 1.05, 'Samples sorted by ' + GeneName + ' expression', horizontalalignment='center', verticalalignment='center', transform=g.ax_heatmap.transAxes, fontsize=14)\n",
    "# Create a color bar for the category labels\n",
    "color_bar = sns.color_palette([color_map[x] for x in ['Negative', 'Medium expressed', 'Highly expressed']])\n",
    "legend = plt.legend(handles=[plt.Rectangle((0, 0), 1, 1, color=color) for color in color_bar], labels=color_map.keys(), bbox_to_anchor=(0.000000000001, -0.05), loc='upper left')\n",
    "# Show the plot\n",
    "plt.savefig(os.path.join(toPlots_directory, f'SortedExpression_{GeneName}_Heatmap.png'), dpi=300)  # Save as PNG with high quality\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b4b2a9",
   "metadata": {},
   "source": [
    "<h1><font color=\"#004D7F\" size=4>3.4. Kaplan-Meier curve.</font></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44883a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_cutoff_forKM(df, genes, value):\n",
    "    # Select only the columns corresponding to the genes\n",
    "    df_subset = df[genes]\n",
    "    print(\"Name of gene:\", genes)\n",
    "    #print(\"Shape of df_subset:\", df_subset.shape)\n",
    "    # Drop rows under positive/negative threshold\n",
    "    df_subset = df_subset[(df_subset > value).any(axis=1)].dropna()\n",
    "    # Fit an exponential distribution to the data\n",
    "    params = expon.fit(df_subset.values.ravel())\n",
    "    # Generate samples from the fitted distribution\n",
    "    samples = expon.rvs(*params, size=1000)\n",
    "    # Cluster the samples using DBSCAN\n",
    "    dbscan = DBSCAN(eps=0.1, min_samples=5)\n",
    "    labels = dbscan.fit_predict(samples.reshape(-1, 1))\n",
    "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "    #print(\"Finding optimal cutoff...\")\n",
    "    # Check if there are at least two clusters\n",
    "    if len(unique_labels) >= 2:\n",
    "        # Sort clusters by size\n",
    "        sorted_clusters = sorted(zip(unique_labels, counts), key=lambda x: x[1], reverse=True)\n",
    "        # Calculate the difference between the means of the two largest clusters\n",
    "        cluster1_indices = np.where(labels == sorted_clusters[0][0])[0]\n",
    "        cluster2_indices = np.where(labels == sorted_clusters[1][0])[0]\n",
    "        cluster1_mean = np.mean(samples[cluster1_indices])\n",
    "        cluster2_mean = np.mean(samples[cluster2_indices])\n",
    "        diff = np.abs(cluster1_mean - cluster2_mean)\n",
    "        # Update optimal cutoff and optimal difference if difference is maximized\n",
    "        optimal_cutoff = np.min([cluster1_mean, cluster2_mean])\n",
    "        optimal_diff = diff\n",
    "        optimal_labels = labels\n",
    "        min_input = np.min(df_subset)\n",
    "        max_input = np.max(df_subset)\n",
    "    else:\n",
    "        print(\"No optimal cutoff found greater than PosNegCriteria. Returning default values.\")\n",
    "        return value, None, None, None\n",
    "    # Sort dataframe based on the selected gene in descending order\n",
    "    sorted_df = df.sort_values(by=genes[0], ascending=False)\n",
    "    sample_names = sorted_df.index  # Extract sample names from index\n",
    "    return optimal_cutoff, optimal_diff, optimal_labels, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289b4718-d058-47c8-8779-e1875814805d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Drop rows with missing or non-numeric values\n",
    "df = df.dropna(subset=['days_to_death', 'vital_status'])\n",
    "df = df[pd.to_numeric(df['days_to_death'], errors='coerce').notnull()]  # Ensure 'days_to_death' contains numeric values\n",
    "df['days_to_death'] = pd.to_numeric(df['days_to_death'], errors='coerce')\n",
    "# Convert 'vital_status' to categorical values\n",
    "df['vital_status'] = df['vital_status'].astype('category')\n",
    "# Plotting\n",
    "num_cols = 4\n",
    "num_rows = (len(column_order) + num_cols - 1) // num_cols  # Calculate the number of rows needed\n",
    "\n",
    "plt.figure(figsize=(15, 4 * num_rows))  # Adjust figure size based on the number of rows\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Iterate over each gene column\n",
    "for i, gene in enumerate(column_order):\n",
    "    plt.subplot(num_rows, num_cols, i + 1)\n",
    "    cutoff_value, optimal_diff, optimal_labels, optimal_centroids = find_optimal_cutoff_forKM(df, [gene], 0)\n",
    "    # Filter the data based on gene expression levels\n",
    "    high_expr_data = df[df[gene] > cutoff_value]\n",
    "    medium_expr_data = df[(df[gene] > 0) & (df[gene] <= cutoff_value)]\n",
    "    negative_expr_data = df[df[gene] == 0]  # Filter for values equal to 0\n",
    "    #print(f' {high_expr_data.shape[0]},{medium_expr_data.shape[0]},{negative_expr_data.shape[0]}, {high_expr_data.shape[0]+medium_expr_data.shape[0]+negative_expr_data.shape[0]}' )\n",
    "    # Check if there are no negative expression data points\n",
    "    if negative_expr_data.shape[0] == 0:\n",
    "        # Fit the Kaplan-Meier curve for high expression data\n",
    "        kmf = KaplanMeierFitter()\n",
    "        kmf.fit(durations=high_expr_data['days_to_death']/365, event_observed=high_expr_data['vital_status'] == 'Dead', label='High Expression')\n",
    "        kmf.plot(ci_show=False)\n",
    "        # Fit the Kaplan-Meier curve for medium expression data if there are entries\n",
    "        if not medium_expr_data.empty:\n",
    "            kmf.fit(durations=medium_expr_data['days_to_death']/365, event_observed=medium_expr_data['vital_status'] == 'Dead', label='Medium Expression')\n",
    "            kmf.plot(ci_show=False)\n",
    "    else:\n",
    "        positive_expr_data = pd.concat([high_expr_data, medium_expr_data])\n",
    "        # Create a KaplanMeierFitter object\n",
    "        kmf = KaplanMeierFitter()\n",
    "        # Fit the Kaplan-Meier curve for positive expression data\n",
    "        kmf.fit(durations=positive_expr_data['days_to_death']/365, event_observed=positive_expr_data['vital_status'] == 'Dead', label='Positive Expression')\n",
    "        kmf.plot(ci_show=False)\n",
    "        if not negative_expr_data.empty:\n",
    "            kmf.fit(durations=negative_expr_data['days_to_death']/365, event_observed=negative_expr_data['vital_status'] == 'Dead', label='Negative Expression')\n",
    "            kmf.plot(ci_show=False)\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Time (years)')\n",
    "    plt.ylabel('Survival Probability')\n",
    "    plt.title(f'Kaplan-Meier Curve for {gene} \\n High: {high_expr_data.shape[0]} | Medium: {medium_expr_data.shape[0]} | Negative: {negative_expr_data.shape[0]}')\n",
    "    # Add legend\n",
    "    plt.legend()\n",
    "plt.tight_layout()  # Adjust subplot layout to prevent overlap\n",
    "plt.savefig(os.path.join(toPlots_directory, f'Kaplan-Meier.png'), dpi=300)  # Save as PNG with high quality\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633a72ea",
   "metadata": {},
   "source": [
    "<h1><font color=\"#004D7F\" size=5>4. DEA experimental design </font></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a1cf98",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "################ CREATING FILES TO DEA  ##############################################\n",
    "dataset_raw='/Users/TTUSVM/Documents/GitHub/TCGA-TTU/TC3R/Input/240328_TCGA-{projectName}_raw-counts.csv'\n",
    "data_raw= pd.read_csv(dataset_raw, sep=',',index_col=0)\n",
    "raw = pd.DataFrame(data_raw)\n",
    "transposed_raw= raw.transpose()\n",
    "columnExample= [\"MAGEA1\"]\n",
    "# Iterate over each gene column\n",
    "for i, gene in enumerate(columnExample):\n",
    "    cutoff_value, optimal_diff, optimal_labels, optimal_centroids = find_optimal_cutoff_forKM(df, [gene], 0)\n",
    "    # Filter the data based on gene expression levels\n",
    "    high_expr_data = df[df[gene] > cutoff_value]\n",
    "    medium_expr_data = df[(df[gene] > 0) & (df[gene] <= cutoff_value)]\n",
    "    negative_expr_data = df[df[gene] == 0]\n",
    "    minimumSamples=3 # minimum of samples per category to perform DEA\n",
    "    if cutoff_value ==0:\n",
    "        if int(negative_expr_data.shape[0]) >= minimumSamples:\n",
    "            positive_expr_data = pd.concat([high_expr_data, medium_expr_data])\n",
    "            print(f'Creating Negative ({negative_expr_data.shape[0]}) vs Positive ({positive_expr_data.shape[0]}) cls file')\n",
    "            # obtaining samples names\n",
    "            positiveSamples=positive_expr_data.index\n",
    "            negativeSamples=negative_expr_data.index\n",
    "            #Creating dataframes\n",
    "            negativesdf=pd.DataFrame(negativeSamples)\n",
    "            negativesdf['condition']= 'Control'\n",
    "            positivesdf= pd.DataFrame(positiveSamples)\n",
    "            positivesdf['condition']= 'Treatment'\n",
    "            #merging and writing to csv\n",
    "            combined_df = pd.concat([negativesdf, positivesdf], ignore_index=True)\n",
    "            filename=os.path.join(deainput_directory, f\"{formatted_date}_TCGA_{projectName}_{gene}_NEGvsPOS_DES.csv\")\n",
    "            filename_raw= os.path.join(deainput_directory, f\"{formatted_date}_TCGA_{projectName}_{gene}_NEGvsPOS_RAW.csv\")\n",
    "            TotalIndex = combined_df['sample']\n",
    "            transposed_sorted = transposed_raw[TotalIndex]\n",
    "            transposed_sorted.to_csv(filename_raw, index=True)\n",
    "            combined_df.to_csv(filename, index=False)\n",
    "            print(f'Combined data has been written to: {filename} \\n')\n",
    "        else:\n",
    "            print(f'Please modify positive/negative cutoff to have at least 3 samples per category. Current: {negative_expr_data.shape[0]} negative samples and {positive_expr_data.shape[0]} positive samples\\n')\n",
    "    else:  \n",
    "        if medium_expr_data.shape[0] >=minimumSamples and high_expr_data.shape[0] >=minimumSamples and negative_expr_data.shape[0] >=minimumSamples: #all categories accomplished\n",
    "            print(f'Creating Medium ({medium_expr_data.shape[0]})  vs High ({high_expr_data.shape[0]}), Negative ({negative_expr_data.shape[0]}) vs High ({high_expr_data.shape[0]}), and Negative ({negative_expr_data.shape[0]}) vs Medium ({medium_expr_data.shape[0]})cls files')\n",
    "             # obtaining samples names\n",
    "            highSamples=high_expr_data.index\n",
    "            mediumSamples = medium_expr_data.index\n",
    "            negativeSamples=negative_expr_data.index\n",
    "            #merging and writing to csv\n",
    "            mediumdf=pd.DataFrame(mediumSamples)\n",
    "            mediumdf['condition']= 'Control'\n",
    "            highdf= pd.DataFrame(highSamples)\n",
    "            highdf['condition']= 'Treatment'\n",
    "            combined_df = pd.concat([mediumdf, highdf], ignore_index=True)\n",
    "            filename=os.path.join(deainput_directory, f\"{formatted_date}_TCGA_{projectName}_{gene}_MEDvsHIG_DES.csv\")\n",
    "            filename_raw= os.path.join(deainput_directory, f\"{formatted_date}_TCGA_{projectName}_{gene}_MEDvsHIG_RAW.csv\")\n",
    "            TotalIndex = combined_df['sample']\n",
    "            transposed_sorted = transposed_raw[TotalIndex]\n",
    "            transposed_sorted.to_csv(filename_raw, index=True)        \n",
    "            combined_df.to_csv(filename, index=False)\n",
    "            print(f'Combined data has been written to: {filename}')\n",
    "            \n",
    "            negativesdf=pd.DataFrame(negativeSamples)\n",
    "            negativesdf['condition']= 'Control'\n",
    "            highdf= pd.DataFrame(highSamples)\n",
    "            highdf['condition']= 'Treatment'\n",
    "            combined2_df = pd.concat([negativesdf, highdf], ignore_index=True)\n",
    "            print(f'{combined2_df}')\n",
    "            filename=os.path.join(deainput_directory, f\"{formatted_date}_TCGA_{projectName}_{gene}_NEGvsHIG_DES.csv\")\n",
    "            filename_raw= os.path.join(deainput_directory, f\"{formatted_date}_TCGA_{projectName}_{gene}_NEGvsHIG_RAW.csv\")\n",
    "            TotalIndex = combined2_df['sample']\n",
    "            transposed_sorted = transposed_raw[TotalIndex]\n",
    "            transposed_sorted.to_csv(filename_raw, index=True)\n",
    "            combined2_df.to_csv(filename, index=False)\n",
    "\n",
    "            negativesdf=pd.DataFrame(negativeSamples)\n",
    "            negativesdf['condition']= 'Control'\n",
    "            mediumdf=pd.DataFrame(mediumSamples)\n",
    "            mediumdf['condition']= 'Treatment'\n",
    "            combined3_df = pd.concat([negativesdf, mediumdf], ignore_index=True)\n",
    "            filename=os.path.join(deainput_directory, f\"{formatted_date}_TCGA_{projectName}_{gene}_NEGvsMED_DES.csv\")\n",
    "            filename_raw= os.path.join(deainput_directory, f\"{formatted_date}_TCGA_{projectName}_{gene}_NEGvsMED_RAW.csv\")\n",
    "            TotalIndex = combined3_df['sample']\n",
    "            transposed_sorted = transposed_raw[TotalIndex]\n",
    "            transposed_sorted.to_csv(filename_raw, index=True)\n",
    "            combined3_df.to_csv(filename, index=False)\n",
    "            print(f'Combined data has been written to: {filename}\\n')\n",
    "            \n",
    "        elif medium_expr_data.shape[0] <minimumSamples or high_expr_data.shape[0] <minimumSamples and negative_expr_data.shape[0] >=minimumSamples: #medium or high are insufficient\n",
    "            positive_expr_data = pd.concat([high_expr_data, medium_expr_data])\n",
    "            print(f'Creating Negative ({negative_expr_data.shape[0]}) vs Positive ({positive_expr_data.shape[0]}) cls file due to small (<3) sample size for High ({high_expr_data.shape[0]}) or Medium ({medium_expr_data.shape[0]}) categories')        \n",
    "            # obtaining samples names\n",
    "            positiveSamples=positive_expr_data.index\n",
    "            negativeSamples=negative_expr_data.index\n",
    "            #Creating dataframes\n",
    "            negativesdf=pd.DataFrame(negativeSamples)\n",
    "            negativesdf['condition']= 'Control'\n",
    "            positivesdf= pd.DataFrame(positiveSamples)\n",
    "            positivesdf['condition']= 'Treatment'\n",
    "            #merging and writing to csv\n",
    "            combined_df = pd.concat([negativesdf, positivesdf], ignore_index=True)\n",
    "            filename=os.path.join(deainput_directory, f\"{formatted_date}_TCGA_{projectName}_{gene}_NEGvsPOS_DES.csv\")\n",
    "            filename_raw= os.path.join(deainput_directory, f\"{formatted_date}_TCGA_{projectName}_{gene}_NEGvsPOS_RAW.csv\")\n",
    "            TotalIndex = combined_df['sample']\n",
    "            transposed_sorted = transposed_raw[TotalIndex]\n",
    "            transposed_sorted.to_csv(filename_raw, index=True)\n",
    "            combined_df.to_csv(filename, index=False)\n",
    "            print(f'Combined data has been written to: {filename}\\n')\n",
    "        elif negative_expr_data.shape[0] <minimumSamples and (medium_expr_data.shape[0] <minimumSamples or high_expr_data.shape[0] <minimumSamples): #Only medium or only High\n",
    "            print(f'Please modify positive/negative cutoff to have at least 3 samples per category. Current: {negative_expr_data.shape[0]} negative, {medium_expr_data.shape[0]} medium ,and {high_expr_data.shape[0]} high samples\\n')\n",
    "        else: #Case for typical Type 2 gene (Negative <3 and samples are into High and medium)\n",
    "            print(f'Creating High ({high_expr_data.shape[0]}) vs Medium ({medium_expr_data.shape[0]}) cls file due to small (<3) sample size for Negative category ({negative_expr_data.shape[0]})')\n",
    "            # obtaining samples names\n",
    "            highSamples=high_expr_data.index\n",
    "            mediumSamples = medium_expr_data.index\n",
    "            #Creating dataframes\n",
    "            mediumdf=pd.DataFrame(mediumSamples)\n",
    "            mediumdf['condition']= 'Control'\n",
    "            highdf= pd.DataFrame(highSamples)\n",
    "            highdf['condition']= 'Treatment'\n",
    "            #merging and writing to csv\n",
    "            combined_df = pd.concat([mediumdf, highdf], ignore_index=True)\n",
    "            filename=os.path.join(deainput_directory, f\"{formatted_date}_TCGA_{projectName}_{gene}_MEDvsHIG_DES.csv\")\n",
    "            filename_raw= os.path.join(deainput_directory, f\"{formatted_date}_TCGA_{projectName}_{gene}_MEDvsHIG_RAW.csv\")\n",
    "            TotalIndex = combined_df['sample']\n",
    "            transposed_sorted = transposed_raw[TotalIndex]\n",
    "            transposed_sorted.to_csv(filename_raw, index=True)\n",
    "            combined_df.to_csv(filename, index=False)\n",
    "            print(f'Combined data has been written to: {filename}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d17f618",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_raw='/Users/TTUSVM/Documents/GitHub/TCGA-TTU/TC3R/Input/240328_TCGA-{projectName}_raw-counts.csv'\n",
    "data_raw= pd.read_csv(dataset_raw, sep=',',index_col=0)\n",
    "raw = pd.DataFrame(data_raw)\n",
    "transposed_raw= raw.transpose()\n",
    "transposed_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1a7c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transposed_raw.shape)\n",
    "mediumList=['TCGA-02-0047', 'TCGA-02-2486', 'TCGA-06-0125', 'TCGA-06-0129',\n",
    "       'TCGA-06-0138', 'TCGA-06-0139', 'TCGA-06-0190', 'TCGA-06-0210',\n",
    "       'TCGA-06-0686', 'TCGA-06-0749', 'TCGA-06-0878', 'TCGA-06-0882',\n",
    "       'TCGA-06-1804', 'TCGA-06-2557', 'TCGA-06-2564', 'TCGA-06-2565',\n",
    "       'TCGA-06-2567', 'TCGA-06-2569', 'TCGA-06-2570', 'TCGA-06-5410',\n",
    "       'TCGA-06-5411', 'TCGA-06-5414', 'TCGA-06-5856', 'TCGA-06-5858',\n",
    "       'TCGA-06-5859', 'TCGA-12-0616', 'TCGA-12-0618', 'TCGA-12-1597',\n",
    "       'TCGA-14-1034', 'TCGA-14-1402', 'TCGA-14-1823', 'TCGA-14-1829',\n",
    "       'TCGA-14-2554', 'TCGA-15-1444', 'TCGA-19-1787', 'TCGA-19-2629',\n",
    "       'TCGA-26-1442', 'TCGA-26-5132', 'TCGA-26-5134', 'TCGA-26-5135',\n",
    "       'TCGA-27-1834', 'TCGA-27-1835', 'TCGA-27-2519', 'TCGA-27-2523',\n",
    "       'TCGA-27-2526', 'TCGA-27-2528', 'TCGA-28-2514', 'TCGA-28-5209',\n",
    "       'TCGA-28-5213', 'TCGA-28-5215', 'TCGA-28-5218', 'TCGA-28-5220',\n",
    "       'TCGA-32-1980', 'TCGA-32-1982', 'TCGA-32-2638', 'TCGA-32-4213',\n",
    "       'TCGA-32-5222', 'TCGA-41-2571', 'TCGA-41-2572', 'TCGA-41-3915',\n",
    "       'TCGA-41-5651', 'TCGA-76-4926', 'TCGA-76-4927', 'TCGA-76-4931',\n",
    "       'TCGA-76-4932']\n",
    "\n",
    "filtercito=transposed_raw[mediumList]\n",
    "print(filtercito.shape)\n",
    "filtercito.head()\n",
    "filtercito.to_csv('cositohermoso', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
